[
  {
    "objectID": "sessions/api.html",
    "href": "sessions/api.html",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "",
    "text": "Pour installer toutes les dépendances nécessaires pour ce tutoriel, vous pouvez taper, en ligne de commande:"
  },
  {
    "objectID": "sessions/api.html#comprendre-le-principe-avec-un-exemple-interactif",
    "href": "sessions/api.html#comprendre-le-principe-avec-un-exemple-interactif",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "2.1 Comprendre le principe avec un exemple interactif",
    "text": "2.1 Comprendre le principe avec un exemple interactif\nLe premier mode (accès par un navigateur) est principalement utilisé lorsqu’une interface web permet à un utilisateur de faire des choix afin de lui renvoyer des résultats correspondant à ceux-ci. Prenons à nouveau l’exemple de l’API de géolocalisation que nous utiliserons dans ce chapitre. Imaginons une interface web permettant à l’utilisateur deux choix : un code postal et une adresse. Cela sera injecté dans la requête et le serveur répondra avec la géolocalisation adaptée.\n\n\n\nviewof codePostal = Inputs.text({value: \"92120\", placeholder: \"92120\", label: md`**Code Postal**`})\n\n\n\n\n\n\n\n\n\n\nviewof adresse = Inputs.text({value: defaultAdresse, placeholder: defaultAdresse, label: md`**Adresse**`})\n\n\n\n\n\n\n\n\n\nmd`\n${\nawait mj`$$\\underbrace{\\text{${apiroot}}}_{\\text{API root}}/\\underbrace{\\text{search}}_{\\text{API endpoint}}/?\\underbrace{\\text{${param1}}}_{\\text{main parameter}}\\&\\underbrace{\\text{${param2}}}_{\\text{additional parameter}}$$`\n}\n`\n\n\n\n\n\n\n\nmap = {\n  const container = html`&lt;div style=\"height:300px;\"&gt;`;\n  yield container;\n  const map = L.map(container).setView([latitude, longitude], 13);\n  L.tileLayer(\"https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png\", {\n    attribution: \"&copy; &lt;a href=https://www.openstreetmap.org/copyright&gt;OpenStreetMap&lt;/a&gt; contributors\"\n  }).addTo(map);\n  var marker = L.marker([latitude, longitude]).addTo(map);\n  marker.bindPopup(\"&lt;b&gt;Trouvé !&lt;/b&gt;\").openPopup();\n  return map\n}\n\n\n\n\n\n\n🔎 Allons voir ce que cela donne dans l’onglet Réseau des outils de développement de notre navigateur (dans firefox, raccourci  CTRL+MAJ+K).\n\nhtml`\n Pour preuve que cette requête est bien fonctionnelle, on peut l'ouvrir dans un navigateur : &lt;a href=\"${url}\" target=\"_blank\" title=\"Test de url dans un navigateur\"&gt;\n &lt;i class=\"fa-solid fa-magnifying-glass\"&gt;&lt;/i&gt;&lt;/i&gt;\n`\n\n\n\n\n\n\nCe qui nous donne un output au format JSON, le format de sortie d’API le plus commun.\nSi on veut un beau rendu, comme la carte ci-dessus, il faudra que le navigateur retravaille cet output, ce qui se fait normalement avec Javascript, le langage de programmation embarqué par les navigateurs."
  },
  {
    "objectID": "sessions/api.html#comment-faire-avec-python",
    "href": "sessions/api.html#comment-faire-avec-python",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "2.2 Comment faire avec Python  ?",
    "text": "2.2 Comment faire avec Python  ?\nLe principe est le même sauf que nous perdons l’aspect interactif. Il s’agira donc, avec Python, de construire l’URL voulue et d’aller chercher via une requête HTTP le résultat.\nPython communique avec internet : via le package requests. Ce package suit le protocole HTTP où on retrouve principalement deux types de requêtes : GET et POST :\n\nLa requête GET est utilisée pour récupérer des données depuis un serveur web. C’est la méthode la plus simple et courante pour accéder aux ressources d’une page web. Nous allons commencer par décrire celle-ci.\nLa requête POST est utilisée pour envoyer des données au serveur, souvent dans le but de créer ou de mettre à jour une ressource. Sur les pages web, elle sert souvent à la soumission de formulaires qui nécessitent de mettre à jour des informations sur une base (mot de passe, informations clients, etc.). Nous verrons son utilité plus tard, lorsque nous commencerons à rentrer dans les requêtes authentifiées où il faudra soumettre des informations supplémentaires à notre requête.\n\nFaisons un premier test avec Python en faisant comme si nous connaissions bien cette API.\n\nimport requests\nadresse = \"88 avenue verdier\"\nurl_ban_example = f\"https://api-adresse.data.gouv.fr/search/?q={adresse.replace(\" \", \"+\")}&postcode=92120\"\nrequests.get(url_ban_example)\n\n&lt;Response [200]&gt;\n\n\nQu’est-ce qu’on obtient ? Un code HTTP. Le code 200 correspond aux requêtes réussies, c’est-à-dire pour lesquelles le serveur est en mesure de répondre. Si ce n’est pas le cas, pour une raison x ou y, vous aurez un code différent.\n\n\n\n\n\n\nLes codes HTTP\n\n\n\n\n\nLes codes de statut HTTP sont des réponses standard envoyées par les serveurs web pour indiquer le résultat d’une requête effectuée par un client (comme un navigateur ou un script Python). Ils sont classés en différentes catégories selon le premier chiffre du code :\n\n1xx : Informations\n2xx : Succès\n3xx : Redirections\n4xx : Erreurs côté client\n5xx : Erreurs côté serveur\n\nCeux à retenir sont : 200 (succès), 400 (requête mal structurée), 401 (authentification non réussie), 403 (accès interdit), 404 (ressource demandée n’existe pas), 503 (le serveur n’est pas en capacité de répondre)\n\n\n\nPour récupérer le contenu renvoyé par requests, il existe plusieurs méthodes. Quand on un JSON bien formatté, le plus simple est d’utiliser la méthode json qui transforme cela en dictionnaire :\n\nreq = requests.get(url_ban_example)\nlocalisation_insee = req.json()\nlocalisation_insee\n\n{'type': 'FeatureCollection',\n 'features': [{'type': 'Feature',\n   'geometry': {'type': 'Point', 'coordinates': [2.309144, 48.81622]},\n   'properties': {'label': '88 Avenue Verdier 92120 Montrouge',\n    'score': 0.9735636363636364,\n    'housenumber': '88',\n    'id': '92049_9625_00088',\n    'banId': '92dd3c4a-6703-423d-bf09-fc0412fb4f89',\n    'name': '88 Avenue Verdier',\n    'postcode': '92120',\n    'citycode': '92049',\n    'x': 649270.67,\n    'y': 6857572.24,\n    'city': 'Montrouge',\n    'context': '92, Hauts-de-Seine, Île-de-France',\n    'type': 'housenumber',\n    'importance': 0.7092,\n    'street': 'Avenue Verdier',\n    '_type': 'address'}}]}\n\n\n\n\n\n\n\nEn l’occurrence, on voit que les données sont dans un JSON imbriqué. Il faut donc développer un peu de code pour récupérer les informations voulues dans celui-ci:\n\nlocalisation_insee.get('features')[0].get('properties')\n\n\n\n\n\n\nC’est là l’inconvénient principal de l’usage des API : le travail ex post sur les données renvoyées est parfois important. Le code nécessaire est propre à chaque API puisque l’architecture du JSON dépend de chaque API."
  },
  {
    "objectID": "sessions/api.html#comment-connaître-les-inputs-et-outputs-des-api",
    "href": "sessions/api.html#comment-connaître-les-inputs-et-outputs-des-api",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "2.3 Comment connaître les inputs et outputs des API ?",
    "text": "2.3 Comment connaître les inputs et outputs des API ?\nIci on a pris l’API BAN comme un outil magique dont on connaissait les principaux inputs (le endpoint, les paramètres et leur formattage…). Mais comment faire, en pratique, pour en arriver là ? Tout simplement en lisant la documentation lorsqu’elle existe et en testant celle-ci via des exemples.\nLes bonnes API proposent un outil interactif qui s’appelle le swagger. C’est un site web interactif où sont décrites les principales fonctionnalités de l’API et où l’utilisateur peut tester des exemples interactivement. Ces documentations sont souvent créées automatiquement lors de la construction d’une API et mises à disposition par le biais d’un point d’entrée /docs. Elles permettent souvent d’éditer certains paramètres dans le navigateur, voir le JSON obtenu (ou l’erreur générée) et récupérer la requête formattée qui permet d’obtenir celui-ci. Ces consoles interactives dans le navigateur permettent de répliquer le tâtonnement qu’on peut faire par ailleurs dans des outils spécialisés comme postman.\nConcernant l’API BAN, la documentation se trouve sur https://adresse.data.gouv.fr/api-doc/adresse. Elle n’est pas interactive, malheureusement. Mais elle présente de nombreux exemples qui peuvent être testés directement depuis le navigateur. Il suffit d’utiliser les URL proposées comme exemple. Ceux-ci sont présentés par le biais de curl (un équivalent de requests en ligne de commande Linux ):\ncurl \"https://api-adresse.data.gouv.fr/search/?q=8+bd+du+port&limit=15\"\nIl suffit de copier l’URL en question (https://api-adresse.data.gouv.fr/search/?q=8+bd+du+port&limit=15), d’ouvrir un nouvel onglet et vérifier que cela produit bien un résultat. Puis de changer un paramètre et vérifier à nouveau, jusqu’à trouver la structure qui convient. Et après, on peut passer à Python comme le propose l’exercice suivant."
  },
  {
    "objectID": "sessions/api.html#application",
    "href": "sessions/api.html#application",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "2.4 Application",
    "text": "2.4 Application\nPour la prochaine application, nous allons utiliser l’adresse suivante :\n\nadresse = \"88 Avenue Verdier\"\n\n\n\n\n\n\n\nExercice 1 : Structurer un appel à une API depuis Python\n\n\n\n\nTester sans aucun autre paramètre, le retour de notre API. Transformer en DataFrame le résultat.\nSe restreindre à Montrouge avec le paramètre ad hoc et la recherche du code insee ou code postal adéquat sur Google.\n(Optionnel) : Représenter l’adresse trouvée sur une carte.\n\n\n\n\n\nCorrection question 1\nimport requests\nimport pandas as pd\n\nban_root = \"https://api-adresse.data.gouv.fr\"\nban_search_endpoint = \"search\"\napi_ban_q1 = f\"{ban_root}/{ban_search_endpoint}?q={adresse.replace(\" \", \"+\")}\"\noutput_api_ban = requests.get(api_ban_q1).json().get('features')\n\ndf_avenue_verdier = pd.DataFrame(\n    [out['properties'] for out in output_api_ban]\n)\n\n\nLes deux premières lignes du dataframe obtenu à la question 1 devraient être\n\n\n\n\n\n\n\n\n\nlabel\nscore\nhousenumber\nid\nbanId\nname\npostcode\ncitycode\nx\ny\ncity\ncontext\ntype\nimportance\nstreet\n_type\nlocality\n\n\n\n\n0\n88 Avenue Verdier 92120 Montrouge\n0.973564\n88\n92049_9625_00088\n92dd3c4a-6703-423d-bf09-fc0412fb4f89\n88 Avenue Verdier\n92120\n92049\n649270.67\n6857572.24\nMontrouge\n92, Hauts-de-Seine, Île-de-France\nhousenumber\n0.7092\nAvenue Verdier\naddress\nNaN\n\n\n1\nAvenue Verdier 44500 La Baule-Escoublac\n0.719373\nNaN\n44055_3690\nNaN\nAvenue Verdier\n44500\n44055\n291884.83\n6701220.48\nLa Baule-Escoublac\n44, Loire-Atlantique, Pays de la Loire\nstreet\n0.6006\nAvenue Verdier\naddress\nNaN\n\n\n\n\n\n\n\nA la question 2, la requête ne renvoie cette fois qu’une seule observation, qu’on pourrait retravailler avec GeoPandas pour vérifier qu’on a bien placé ce point sur une carte\n\n\nCorrection question 2\nimport pandas as pd\nimport geopandas as gpd\n\napi_ban_q2 = f\"{ban_root}/{ban_search_endpoint}?q={adresse.replace(\" \", \"+\")}&postcode=92120\"\noutput_q2 = requests.get(api_ban_q2).json()\n\noutput_q2 = pd.DataFrame(\n    [output_q2.get(\"features\")[0]['properties']]\n)\noutput_q2 = gpd.GeoDataFrame(\n    output_q2,\n    geometry=gpd.points_from_xy(output_q2.x, output_q2.y), crs=\"EPSG:2154\"\n).to_crs(4326)\noutput_q2\n\n\n\n\n\n\n\n\n\nlabel\nscore\nhousenumber\nid\nbanId\nname\npostcode\ncitycode\nx\ny\ncity\ncontext\ntype\nimportance\nstreet\ngeometry\n\n\n\n\n0\n88 Avenue Verdier 92120 Montrouge\n0.973564\n88\n92049_9625_00088\n92dd3c4a-6703-423d-bf09-fc0412fb4f89\n88 Avenue Verdier\n92120\n92049\n649270.67\n6857572.24\nMontrouge\n92, Hauts-de-Seine, Île-de-France\nhousenumber\n0.7092\nAvenue Verdier\nPOINT (2.30914 48.81622)\n\n\n\n\n\n\n\nEnfin, à la question 3, on obtient cette carte (plus ou moins la même que précédemment) :\n\n\nCorrection question 3\nimport folium\n\n# Extraire la longitude et la latitude\nlongitude = output_q2.geometry.x.iloc[0]\nlatitude = output_q2.geometry.y.iloc[0]\n\n# Créer une carte Folium centrée sur le point\nm = folium.Map(location=[latitude, longitude], zoom_start=16)\n\n# Définir le contenu de la popup\npopup_content = f\"\"\"\n&lt;b&gt;{output_q2['name'].iloc[0]}&lt;/b&gt; has been found!\n\"\"\"\n\n# Ajouter le marqueur\nfolium.Marker(\n    location=[latitude, longitude],\n    popup=folium.Popup(popup_content, max_width=300),\n    icon=folium.Icon(color='blue', icon='info-sign')\n).add_to(m)\n\n# Afficher la carte dans le notebook (si utilisé dans un Jupyter Notebook)\nm\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\n\n\n\n\n\nQuelques exemples d’API à connaître\n\n\n\n\n\nLes principaux fournisseurs de données officielles proposent des API. C’est le cas notamment de l’Insee, d’Eurostat, de la BCE, de la FED, de la Banque Mondiale…\nNéanmoins, la production de données par les institutions publiques est loin d’être restreinte aux producteurs de statistiques publiques. Le portail API gouv est le point de référencement principal pour les API produites par l’administration centrale française ou des administrations territoriales. De nombreuses villes publient également des données sur leurs infrastructures par le biais d’API, par exemple la ville de Paris.\nLes producteurs de données privées proposent également des API. Par exemple, la SNCF ou la RATP proposent des API pour certains usages. Les grands acteurs du numérique, par exemple Spotify  proposent généralement des API pour intégrer certains de leurs services à des applications externes.\nCependant, il faut être conscient des limites de certaines API. En premier lieu, les données partagées ne sont pas forcément très riches pour ne pas compromettre la confidentialité des informations partagées par les utilisateurs du service ou la part de marché du producteur qui n’a pas intérêt à vous partager ses données à forte valeur. Il faut également être conscient du fait qu’une API peut disparaître ou changer de structure du jour au lendemain. Les codes de restructuration de données étant assez adhérents à une structure d’API, on peut se retrouver à devoir changer un volume conséquent de code si une API critique change substantiellement."
  },
  {
    "objectID": "sessions/api.html#source-principale",
    "href": "sessions/api.html#source-principale",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "3.1 Source principale",
    "text": "3.1 Source principale\nNous allons utiliser comme base principale pour ce tutoriel la base permanente des équipements, un répertoire d’équipements publics accueillant du public.\nOn va commencer par récupérer les données qui nous intéressent. On ne récupère pas toutes les variables du fichier mais seulement celles qu’ils nous intéressent : quelques variables sur l’équipement, son adresse et sa commune d’appartenance.\nNous allons nous restreindre aux établissements d’enseignement primaire, secondaire et supérieur du département de la Haute-Garonne (le département 31). Ces établissements sont identifiés par un code particulier, entre C1 et C5.\n\nimport duckdb\n\nquery = \"\"\"\nFROM read_parquet('https://minio.lab.sspcloud.fr/lgaliana/diffusion/BPE23.parquet')\nSELECT NOMRS, NUMVOIE, INDREP, TYPVOIE, LIBVOIE,\n       CADR, CODPOS, DEPCOM, DEP, TYPEQU,\n       concat_ws(' ', NUMVOIE, INDREP, TYPVOIE, LIBVOIE) AS adresse, SIRET\nWHERE DEP = '31'\n      AND starts_with(TYPEQU, 'C')\n      AND NOT (starts_with(TYPEQU, 'C6') OR starts_with(TYPEQU, 'C7'))\n\"\"\"\n\nbpe = duckdb.sql(query)\nbpe = bpe.to_df()\n\nbpe.head(2)\n\n\n\n\n\n\n\n\n\n\n\nNOMRS\nNUMVOIE\nINDREP\nTYPVOIE\nLIBVOIE\nCADR\nCODPOS\nDEPCOM\nDEP\nTYPEQU\nadresse\nSIRET\n\n\n\n\n0\nECOLE PRIMAIRE PUBLIQUE DENIS LATAPIE\n\n\nLD\nLA BOURDETTE\n\n31230\n31001\n31\nC108\nLD LA BOURDETTE\n21310001900024\n\n\n1\nECOLE MATERNELLE PUBLIQUE\n21\n\nCHE\nDE L AUTAN\n\n31280\n31003\n31\nC107\n21 CHE DE L AUTAN\n21310003500038"
  },
  {
    "objectID": "sessions/api.html#récupérer-des-données-à-façon-grâce-aux-api",
    "href": "sessions/api.html#récupérer-des-données-à-façon-grâce-aux-api",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "3.2 Récupérer des données à façon grâce aux API",
    "text": "3.2 Récupérer des données à façon grâce aux API\nNous avons vu précédemment le principe général d’une requête d’API. Pour illustrer, de manière plus massive, la récupération de données par le biais d’une API, essayons de récupérer des données complémentaires à notre source principale. Nous allons utiliser l’annuaire de l’éducation qui fournit de nombreuses informations sur les établissements scolaires. Nous utiliserons le SIRET pour croiser les deux sources de données.\nL’exercice suivant viendra illustrer l’intérêt d’utiliser une API pour avoir des données à façon et la simplicité à récupérer celles-ci via Python. Néanmoins, cet exercice illustrera également une des limites de certaines API, à savoir la volumétrie des données à récupérer.\n\n\n\n\n\n\nExercice 2\n\n\n\n\nVisiter le swagger de l’API de l’Annuaire de l’Education nationale sur api.gouv.fr/documentation, et plus particulièrement sa “documentation externe” qui permet de générer les urls souhaitées en prototypant interactivement les requêtes. Tester une première récupération de données en utilisant le endpoint records sans aucun paramètre.\nPuisqu’on n’a conservé que les données de la Haute Garonne dans notre base principale, on désire ne récupérer que les établissements de ce département par le biais de notre API. Faire une requête avec le paramètre ad hoc, sans en ajouter d’autres.\nAugmenter la limite du nombre de paramètres, voyez-vous le problème ?\nOn va tenter de récupérer ces données par le biais de l’API tabular de data.gouv. Sa documentation est ici et l’identifiant de la ressource est b22f04bf-64a8-495d-b8bb-d84dbc4c7983 (source). Avec l’aide de la documentation, essayer de récupérer des données par le biais de cette API en utilisant le paramètre Code_departement__exact=031 pour ne garder que le département d’intérêt.\nVoyez-vous le problème et comment nous pourrions automatiser la récupération de données ?\n\n\n\n\n\nRéponse question 1\nimport requests\n\nurl_annuaire_education = \"https://data.education.gouv.fr/api/explore/v2.1/catalog/datasets/fr-en-annuaire-education/records\"\n\nschool_q1_exo2 = pd.DataFrame(\n  requests\n  .get(url_annuaire_education)\n  .json()\n  .get(\"results\")\n)\n\nschool_q1_exo2.head(2)\n\n\n\n\n\n\n\n\n\nidentifiant_de_l_etablissement\nnom_etablissement\ntype_etablissement\nstatut_public_prive\nadresse_1\nadresse_2\nadresse_3\ncode_postal\ncode_commune\nnom_commune\n...\nlibelle_nature\ncode_type_contrat_prive\npial\netablissement_mere\ntype_rattachement_etablissement_mere\ncode_circonscription\ncode_zone_animation_pedagogique\nlibelle_zone_animation_pedagogique\ncode_bassin_formation\nlibelle_bassin_formation\n\n\n\n\n0\n0040311S\nEcole primaire publique Pierre Magnan\nEcole\nPublic\n2 avenue Jean des Figues\nLES PLANTIERS\n04200 SISTERON\n04200\n04209\nSisteron\n...\nECOLE DE NIVEAU ELEMENTAIRE\n99\n0040378P\nNone\nNone\n0040032N\n004016\nPAUL ARENE\n02101\nDIGNE SISTERON\n\n\n1\n0400748W\nEcole maternelle\nEcole\nPublic\n53 avenue de la Poste\nNone\n40360 TILH\n40360\n40316\nTilh\n...\nECOLE MATERNELLE\n99\n0400032T\nNone\nNone\n0401054D\n040020\nZAP 040020 DAX\nNone\nNone\n\n\n\n\n2 rows × 72 columns\n\n\n\nNéanmoins, on a deux problèmes : le nombre de lignes et le département d’intérêt. Essayons déjà avec la question 2 de changer ce dernier.\n\n\nRéponse question 2\nurl_31_limite10 = \"https://data.education.gouv.fr/api/explore/v2.1/catalog/datasets/fr-en-annuaire-education/records?where=code_departement%20like%20%22031%22\"\n\nschool_q2_exo2 = pd.DataFrame(\n  requests\n  .get(url_31_limite10)\n  .json()\n  .get(\"results\")\n)\nschool_q2_exo2.head()\n\n\n\n\n\n\n\n\n\nidentifiant_de_l_etablissement\nnom_etablissement\ntype_etablissement\nstatut_public_prive\nadresse_1\nadresse_2\nadresse_3\ncode_postal\ncode_commune\nnom_commune\n...\nlibelle_nature\ncode_type_contrat_prive\npial\netablissement_mere\ntype_rattachement_etablissement_mere\ncode_circonscription\ncode_zone_animation_pedagogique\nlibelle_zone_animation_pedagogique\ncode_bassin_formation\nlibelle_bassin_formation\n\n\n\n\n0\n0310174W\nEcole maternelle publique\nEcole\nPublic\nRue des Ecoles\nNone\n31230 L ISLE EN DODON\n31230\n31239\nL'Isle-en-Dodon\n...\nECOLE MATERNELLE\n99\n0310003K\nNone\nNone\n0311108L\nNone\nNone\n16106\nCOMMINGES\n\n\n1\n0310177Z\nEcole maternelle publique Pierre Fons\nEcole\nPublic\n44 rue Notre Dame\nNone\n31600 MURET\n31600\n31395\nMuret\n...\nECOLE MATERNELLE\n99\n0311319R\nNone\nNone\n0311339M\nNone\nNone\n16107\nMURET\n\n\n2\n0310179B\nEcole maternelle publique Jean Jaurès\nEcole\nPublic\nAllées des Tilleuls\nNone\n31120 PORTET SUR GARONNE\n31120\n31433\nPortet-sur-Garonne\n...\nECOLE MATERNELLE\n99\n0311093V\nNone\nNone\n0311105H\nNone\nNone\n16108\nTOULOUSE SUD-OUEST\n\n\n3\n0310180C\nEcole maternelle publique Jacques Prévert\nEcole\nPublic\n11 rue Désiré\nNone\n31120 PORTET SUR GARONNE\n31120\n31433\nPortet-sur-Garonne\n...\nECOLE MATERNELLE\n99\n0311093V\nNone\nNone\n0311105H\nNone\nNone\n16108\nTOULOUSE SUD-OUEST\n\n\n4\n0310183F\nEcole maternelle publique le pilat\nEcole\nPublic\n1 rue du Dr Ferrand\nNone\n31800 ST GAUDENS\n31800\n31483\nSaint-Gaudens\n...\nECOLE MATERNELLE\n99\n0310083X\nNone\nNone\n0311108L\nNone\nNone\n16106\nCOMMINGES\n\n\n\n\n5 rows × 72 columns\n\n\n\nC’est mieux, mais nous avons toujours seulement 10 observations. Si on essaie d’ajuster le nombre de lignes (question 3), on obtient le retour suivant de l’API :\n\n\nQuestion 3\nurl_31_limite200 = \"https://data.education.gouv.fr/api/explore/v2.1/catalog/datasets/fr-en-annuaire-education/records?where=code_departement%20like%20%22031%22&limit=200\"\n\nrequests.get(url_31_limite200).json()\n\n\n{'error_code': 'InvalidRESTParameterError',\n 'message': 'Invalid value for limit API parameter: 200 was found but -1 &lt;= limit &lt;= 100 is expected.'}\n\n\nEssayons avec des données plus exhaustives : le fichier brut sur data.gouv. Comme on peut le voir dans les métadonnées, on sait qu’on a plus de 1000 écoles dont on peut récupérer des données, mais qu’on en a ici extrait seulement 20. Le champ next nous donne directement l’URL à utiliser pour récupérer les 20 pages suivantes : c’est grâce à lui qu’on a une chance de récupérer toutes nos données d’intérêt.\n\n\nRéponse question 4\nurl_api_datagouv = \"https://tabular-api.data.gouv.fr/api/resources/b22f04bf-64a8-495d-b8bb-d84dbc4c7983/data/?Code_departement__exact=031\"\n\ncall_api_datagouv = requests.get(url_api_datagouv).json()\n\n\nLe problème de la récupération de données via l’API vient du fait que nous ne récupérons qu’un petit échantillon à chaque requête. Pour y remédier, nous allons devoir faire plusieurs appels successifs. Dans le JSON obtenu ci-dessus, la partie intéressante pour automatiser la récupération de nos données est la clé links. En bouclant sur celui-ci pour parcourir la liste des URL accessibles, on peut récupérer des données.\n\n\nRéponse question 5\nimport requests\nimport pandas as pd\n\n# Initialize the initial API URL\nurl_api_datagouv = \"https://tabular-api.data.gouv.fr/api/resources/b22f04bf-64a8-495d-b8bb-d84dbc4c7983/data/?Code_departement__exact=031&page_size=50\"\n\n# Initialize an empty list to store all data entries\nall_data = []\n\n# Initialize the URL for pagination\ncurrent_url = url_api_datagouv\n\n# Loop until there is no next page\nwhile current_url:\n    try:\n        # Make a GET request to the current URL\n        response = requests.get(current_url)\n        response.raise_for_status()  # Raise an exception for HTTP errors\n\n        # Parse the JSON response\n        json_response = response.json()\n\n        # Extract data and append to the all_data list\n        page_data = json_response.get('data', [])\n        all_data.extend(page_data)\n        print(f\"Fetched {len(page_data)} records from {current_url}\")\n\n        # Get the next page URL\n        links = json_response.get('links', {})\n        current_url = links.get('next')  # This will be None if there's no next page\n\n    except requests.exceptions.RequestException as e:\n        print(f\"An error occurred: {e}\")\n        break\n\n\n\nschools_dep31 = pd.DataFrame(all_data)\nschools_dep31.head()\n\n\n\n\n\n\n\n\n__id\nIdentifiant_de_l_etablissement\nNom_etablissement\nType_etablissement\nStatut_public_prive\nAdresse_1\nAdresse_2\nAdresse_3\nCode_postal\nCode_commune\n...\nlibelle_nature\nCode_type_contrat_prive\nPIAL\netablissement_mere\ntype_rattachement_etablissement_mere\ncode_circonscription\ncode_zone_animation_pedagogique\nlibelle_zone_animation_pedagogique\ncode_bassin_formation\nlibelle_bassin_formation\n\n\n\n\n0\n48\n0312140H\nCollège René Cassin\nCollège\nPublic\nAvenue des Carabenes\nNone\nNone\n31650\n31506\n...\nCOLLEGE\n99\n0311850T\nNone\nNone\nNone\nNone\nNone\n16128\nTOULOUSE EST\n\n\n1\n49\n0311266H\nCollège Jean Jaurès\nCollège\nPublic\nPlace Clémence Isaure\nBP 22508\nNone\n31325\n31113\n...\nCOLLEGE\n99\n0311633G\nNone\nNone\nNone\nNone\nNone\n16128\nTOULOUSE EST\n\n\n2\n55\n0312071H\nCollège Jules Verne\nCollège\nPublic\n1 avenue Marcel Pagnol\nNone\nNone\n31830\n31424\n...\nCOLLEGE\n99\n0312071H\nNone\nNone\nNone\nNone\nNone\n16108\nTOULOUSE SUD-OUEST\n\n\n3\n61\n0311632F\nCollège Les Violettes de Aucamville\nCollège\nPublic\n3 avenue des Pins\nNone\nNone\n31140\n31022\n...\nCOLLEGE\n99\n0312139G\nNone\nNone\nNone\nNone\nNone\n16110\nTOULOUSE NORD\n\n\n4\n62\n0311332E\nCollège Anatole France\nCollège\nPublic\n4 avenue de Lespinet\nNone\nNone\n31400\n31555\n...\nCOLLEGE\n99\n0310085Z\nNone\nNone\nNone\nNone\nNone\n16109\nTOULOUSE CENTRE\n\n\n\n\n5 rows × 73 columns\n\n\n\nOn peut fusionner ces nouvelles données avec nos données précédentes pour enrichir celles-ci. Pour faire une production fiable, il faudrait faire attention aux écoles qui ne s’apparient pas, mais ce n’est pas grave pour cette série d’exercices.\n\nbpe_enriched = bpe.merge(\n  schools_dep31,\n  left_on = \"SIRET\",\n  right_on = \"SIREN_SIRET\"\n)\nbpe_enriched.head(2)\n\n\n\n\n\n\n\n\nNOMRS\nNUMVOIE\nINDREP\nTYPVOIE\nLIBVOIE\nCADR\nCODPOS\nDEPCOM\nDEP\nTYPEQU\n...\nlibelle_nature\nCode_type_contrat_prive\nPIAL\netablissement_mere\ntype_rattachement_etablissement_mere\ncode_circonscription\ncode_zone_animation_pedagogique\nlibelle_zone_animation_pedagogique\ncode_bassin_formation\nlibelle_bassin_formation\n\n\n\n\n0\nECOLE PRIMAIRE PUBLIQUE DENIS LATAPIE\n\n\nLD\nLA BOURDETTE\n\n31230\n31001\n31\nC108\n...\nECOLE DE NIVEAU ELEMENTAIRE\n99\n0310003K\nNone\nNone\n0311108L\nNone\nNone\n16106\nCOMMINGES\n\n\n1\nECOLE MATERNELLE PUBLIQUE\n21\n\nCHE\nDE L AUTAN\n\n31280\n31003\n31\nC107\n...\nECOLE MATERNELLE\n99\n0311335H\nNone\nNone\n0311102E\nNone\nNone\n16128\nTOULOUSE EST\n\n\n\n\n2 rows × 85 columns\n\n\n\nCela nous donne des données enrichies de nouvelles caractéristiques sur les établissements. Il y a des coordonnées géographiques dans celles-ci, mais nous allons faire comme s’il n’y en avait pas pour réutiliser notre API de géolocalisation et ainsi avoir un alibi pour utiliser les requêtes POST."
  },
  {
    "objectID": "sessions/api.html#logique",
    "href": "sessions/api.html#logique",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "4.1 Logique",
    "text": "4.1 Logique\nNous avons jusqu’à présent évoqué les requêtes GET. Nous allons maintenant présenter les requêtes POST qui permettent d’interagir de manière plus complexe avec des serveurs de l’API.\nPour découvrir celles-ci, nous allons reprendre l’API de géolocalisation précédente mais utiliser un autre point d’entrée qui nécessite une requête POST.\nCes dernières sont généralement utilisées quand il est nécessaire d’envoyer des données particulières pour déclencher une action. Par exemple, dans le monde du web, si vous avez une authentification à mettre en oeuvre, une requête POST permettra d’envoyer un token au serveur qui répondra en acceptant votre authentification.\nDans notre cas, nous allons envoyer des données au serveur, ce dernier va les recevoir, les utiliser pour la géolocalisation puis nous envoyer une réponse. Pour continuer sur la métaphore culinaire, c’est comme si vous donniez vous-mêmes à la cuisine un tupperware pour récupérer votre plat à emporter."
  },
  {
    "objectID": "sessions/api.html#principe",
    "href": "sessions/api.html#principe",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "4.2 Principe",
    "text": "4.2 Principe\nPrenons cette requête proposée sur le site de documentation de l’API de géolocalisation :\ncurl -X POST -F data=@path/to/file.csv -F columns=voie -F columns=ville -F citycode=ma_colonne_code_insee https://api-adresse.data.gouv.fr/search/csv/\nIci l’objectif est d’obtenir des géolocalisations pour les adresses textuelles présentes dans un fichier .csv.\nComme nous avons pu l’évoquer précédemment, curl est un outil en ligne de commande qui permet de faire des requêtes API. L’option -X POST indique, de manière assez transparente, qu’on désire faire une requête POST.\nLes autres arguments sont passés par le biais des options -F. En l’occurrence, on envoie un fichier et on ajoute des paramètres pour aider le serveur à aller chercher la donnée dedans. L’@ indique que file.csv doit être lu sur le disque et envoyé dans le corps de la requête comme une donnée de formulaire."
  },
  {
    "objectID": "sessions/api.html#application-avec-python",
    "href": "sessions/api.html#application-avec-python",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "4.3 Application avec Python",
    "text": "4.3 Application avec Python\nNous avions requests.get, il est donc logique que nous ayons requests.post. Cette fois, il faudra passer des paramètres à notre requête sous la forme d’un dictionnaire dont les clés sont le nom de l’argument et les valeurs sont des objets Python.\nLe principal défi, illustré dans le prochain exercice, est le passage de l’argument data : il faudra renvoyer le fichier comme un objet Python par le biais de la fonction open.\n\n\n\n\n\n\nExercice 3 : une requête POST pour géolocaliser en masse nos données\n\n\n\n\nEnregistrer au format CSV les colonnes adresse, DEPCOM et Nom_commune de la base d’équipements fusionnée avec notre répertoire précédent (objet bpe_enriched). Il peut être utile, avant l’écriture au format CSV, de remplacer les virgules dans la colonne adresse par des espaces.\nCréer l’objet response avec requests.post et les bons arguments pour géocoder votre CSV.\nTransformer votre output en objet Pandas avec la commande suivante :\n\nbpe_loc = pd.read_csv(io.StringIO(response.text))\n\n\n\n\nRéponse question 1\nimport pathlib\noutput_path = pathlib.Path(\"data/output\")\noutput_path.mkdir(parents=True, exist_ok=True)\ncsv_file = output_path / \"bpe_before_geoloc.csv\"\n\nbpe_enriched[\"adresse\"] = bpe_enriched[\"adresse\"].str.replace(\",\", \"\")\n\nbpe_enriched.loc[:, [\"adresse\", \"DEPCOM\", \"Nom_commune\"]].to_csv(csv_file)\n\n\n\n\nRéponse question 2 et 3\nimport io\n\nparams = {\n    \"columns\": [\"adresse\", \"Nom_commune\"],\n    \"citycode\": \"DEPCOM\",\n    \"result_columns\": [\"result_score\", \"latitude\", \"longitude\"],\n}\n\nresponse = requests.post(\n        \"https://api-adresse.data.gouv.fr/search/csv/\",\n        data=params,\n        files={\"data\": open(csv_file, \"rb\")},\n    )\n\n\nbpe_loc = pd.read_csv(io.StringIO(response.text))\nbpe_loc = bpe_loc.rename({\"Unnamed: 0\": \"index\"}, axis = \"columns\")\n\n\nLes géolocalisations obtenues prennent cette forme\n\n\n\n\n\n\n\n\n\nindex\nadresse\nDEPCOM\nNom_commune\nresult_score\nlatitude\nlongitude\n\n\n\n\n0\n0\nLD LA BOURDETTE\n31001\nAgassac\n0.404609\n43.374288\n0.880679\n\n\n1\n1\n21 CHE DE L AUTAN\n31003\nAigrefeuille\n0.730293\n43.567530\n1.585745\n\n\n\n\n\n\n\nOn peut ensuite faire la jointure à nos données initiales :\n\n\nJointure aux données initiales\nbpe_loc = bpe_loc.loc[:, [\"index\", \"result_score\", \"latitude\", \"longitude\"]]\nbpe_enriched_geocoded = (\n  bpe_enriched\n  .reset_index()\n  .merge(bpe_loc, on = \"index\", suffixes = [\"_annuaire\", \"_ban\"])\n  .drop(\"index\", axis = \"columns\")\n)\n\nbpe_enriched_geocoded.head(2)\n\n\n\n\n\n\n\n\n\nNOMRS\nNUMVOIE\nINDREP\nTYPVOIE\nLIBVOIE\nCADR\nCODPOS\nDEPCOM\nDEP\nTYPEQU\n...\netablissement_mere\ntype_rattachement_etablissement_mere\ncode_circonscription\ncode_zone_animation_pedagogique\nlibelle_zone_animation_pedagogique\ncode_bassin_formation\nlibelle_bassin_formation\nresult_score\nlatitude_ban\nlongitude_ban\n\n\n\n\n0\nECOLE PRIMAIRE PUBLIQUE DENIS LATAPIE\n\n\nLD\nLA BOURDETTE\n\n31230\n31001\n31\nC108\n...\nNone\nNone\n0311108L\nNone\nNone\n16106\nCOMMINGES\n0.404609\n43.374288\n0.880679\n\n\n1\nECOLE MATERNELLE PUBLIQUE\n21\n\nCHE\nDE L AUTAN\n\n31280\n31003\n31\nC107\n...\nNone\nNone\n0311102E\nNone\nNone\n16128\nTOULOUSE EST\n0.730293\n43.567530\n1.585745\n\n\n\n\n2 rows × 88 columns\n\n\n\n\n\nJointure aux données initiales\nbpe_enriched_geocoded = (\n    bpe_enriched_geocoded\n    .dropna(subset=[\"longitude_ban\",\"latitude_ban\"])\n)\n\nbpe_enriched_geocoded = gpd.GeoDataFrame(\n    bpe_enriched_geocoded,\n    geometry=gpd.points_from_xy(\n      bpe_enriched_geocoded['longitude_ban'],\n      bpe_enriched_geocoded['latitude_ban']\n      ),\n    crs=\"EPSG:4326\"\n)\n\n\nPour profiter de nos données enrichies, on peut faire une carte. Pour ajouter un peu de contexte à celle-ci, on peut mettre un fond de carte des communes en arrière plan. Celui-ci peut être récupéré avec cartiflette :\n\n\nRécupération du fond de carte (GEOJSON)\nfrom cartiflette import carti_download\nshp_communes = carti_download(\n  crs = 4326,\n  values = [\"31\"],\n  borders=\"COMMUNE\",\n  vectorfile_format=\"topojson\",\n  filter_by=\"DEPARTEMENT\",\n  source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n  year=2022\n)\nshp_communes.crs = 4326\n\n\n\n\nCode pour la carte interactive\nimport folium\nfrom folium.plugins import MarkerCluster\nimport geopandas as gpd\n\ndepartment_border = shp_communes.dissolve(by=\"INSEE_DEP\")\ncity_borders = shp_communes.copy()\n\nlongitude = bpe_enriched_geocoded.geometry.x.iloc[0]\nlatitude = bpe_enriched_geocoded.geometry.y.iloc[0]\nm = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# Add department border (black, bold)\nfolium.GeoJson(\n    data=department_border,\n    style_function=lambda x: {\n        \"fill\": False,\n        \"color\": \"black\",\n        \"weight\": 3  # Bold border\n    }\n).add_to(m)\n\n# Add city borders (blue, thin)\nfolium.GeoJson(\n    data=city_borders,\n    style_function=lambda x: {\n        \"fill\": False,\n        \"color\": \"blue\",\n        \"weight\": 1  # Thin border\n    }\n).add_to(m)\n\n# Initialize the MarkerCluster\nmarker_cluster = MarkerCluster().add_to(m)\n\ndef generate_popup(row):\n    # Initialiser le contenu avec le nom de l'école\n    popup_content = f\"&lt;b&gt;Nom:&lt;/b&gt; {row['NOMRS']}&lt;br&gt;\"\n\n    # Ajouter \"Ecole élémentaire\" avec une icône ✅️ ou ❌️ selon la valeur\n    ecole_element_status = \"✅️\" if row.get('Ecole_elementaire', False) else \"❌️\"\n    popup_content += f\"&lt;b&gt;Ecole élémentaire:&lt;/b&gt; {ecole_element_status}&lt;br&gt;\"\n\n    # Ajouter \"Nombre d'élèves\" si disponible\n    if not pd.isnull(row.get('Nombre_d_eleves')):\n        popup_content += f\"&lt;b&gt;Nombre d'élèves :&lt;/b&gt; {row['Nombre_d_eleves']}&lt;br&gt;\"\n\n    # Ajouter \"Voie générale\" si disponible\n    if not pd.isnull(row.get('Voie_generale')):\n        popup_content += f\"&lt;b&gt;Voie générale :&lt;/b&gt; {row['Voie_generale']}&lt;br&gt;\"\n\n    # Ajouter \"Voie technologique\" si disponible\n    if not pd.isnull(row.get('Voie_technologique')):\n        popup_content += f\"&lt;b&gt;Voie technologique :&lt;/b&gt; {row['Voie_technologique']}&lt;br&gt;\"\n\n    return popup_content\n\n\n# Add GeoDataFrame points to the MarkerCluster\nfor _, row in bpe_enriched_geocoded.iterrows():\n    # Create the popup content\n    popup_content = generate_popup(row)\n\n    popup = folium.Popup(popup_content, max_width=300)\n\n    # Add the marker to the cluster\n    folium.Marker(\n        location=[row.geometry.y, row.geometry.x],  # Extract latitude and longitude\n        popup=popup,\n        icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n    ).add_to(marker_cluster)\n\n# Display the map inline (optional for Jupyter Notebooks)\nm\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook"
  },
  {
    "objectID": "sessions/api.html#bonnes-pratiques-pour-utiliser-un-token-dans-un-code-sans-le-révéler",
    "href": "sessions/api.html#bonnes-pratiques-pour-utiliser-un-token-dans-un-code-sans-le-révéler",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "5.1 Bonnes pratiques pour utiliser un token dans un code sans le révéler 👮",
    "text": "5.1 Bonnes pratiques pour utiliser un token dans un code sans le révéler 👮\nLes tokens sont des informations personnelles qui ne doivent pas être partagées. Ils n’ont donc pas vocation à apparaître dans le code.\nComme ceci est évoqué à plusieurs reprises dans le cours de mise en production en 3e année de l’ENSAE, il est important de séparer le code des éléments de configuration :\n\nL’idée est de trouver une recette pour apporter les éléments de configuration avec le code mais sans mettre ceux-ci en clair dans le code. L’idée générale sera de stocker la valeur du token dans une variable mais ne jamais révéler celle-ci dans le code. Comment faire dès lors pour déclarer la valeur du jeton sans que celui-ci soit apparent dans le code ?\n\nPour un code amené à fonctionner de manière interactive (par exemple par le biais d’un notebook), il est possible de créer une boite de dialogue qui injectera la valeur renseignée dans une variable. Cela se fait par le biais du package getpass.\nPour le code qui tourne en non interactif, par exemple par le biais de la ligne de commande, l’approche par variable d’environnement est la plus fiable, à condition de faire attention à ne pas mettre le fichier de mot de passe dans Git . Pour cela, le plus simple est d’utiliser dotenv si vous faites tourner votre code ou des secrets si votre code tourne par le biais de l’intégration continue2.\n\n\n\n\n\n\n\nImportant\n\n\n\n\n\nIl ne faut jamais mettre de token dans Git. Sinon, vous courrez le risque d’avoir votre identité usurpée : des robots scannent en continu Github à la recherche de jetons pour ensuite lancer des dénis de service en se faisant passer pour vous.\nSi vous avez partagé par erreur un jeton : pas de panique, cela peut arriver ! L’avantage des jetons est qu’ils sont révocables : vous pouvez l’invalider et en créer un nouveau pour continuer à utiliser le service désiré. La bonne réaction consiste à révoquer le jeton le plus vite possible, une fois la fuite constatée. La meilleure parade pour éviter ce type de fuite est d’ajouter tout de suite le .env au .gitignore.\n\n\n\nL’exercice 5 permettra de mettre en oeuvre ces deux méthodes. Ces méthodes nous serviront à ajouter de manière confidentielle un payload à des requêtes d’authentification, c’est-à-dire des informations confidentielles identifiantes en complément d’une requête."
  },
  {
    "objectID": "sessions/api.html#le-portail-des-api-de-linsee",
    "href": "sessions/api.html#le-portail-des-api-de-linsee",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "5.2 Le portail des API de l’Insee",
    "text": "5.2 Le portail des API de l’Insee\nPour illustrer l’utilisation des API authentifiées, nous proposons d’explorer le portail des API de l’Insee.\nNous allons nous concentrer sur l’API Sirene mais, sur ce portail, il en existe d’autres, notamment l’API Melodi consacrée à la récupération d’un certain nombre de sources open data de l’Insee. L’API Sirene est une version interrogeable des données Sirene open data.\n\n\n\n\n\n\nExercice 4 : API authentifiée par le biais du navigateur\n\n\n\n\nSe créer un compte sur le portail des API\nAller voir l’espace Mes applications et en créer une nouvelle. Par simplicité, vous pouvez la nommer “Atelier SSPHub”.\nDans celle-ci, aller dans l’onglet “Clefs et jetons”.Créer un jeton (vous pouvez laisser la durée de validité proposée).\nCliquer sur l’onglet Souscriptions. Choisir l’API Sirene.\nA droite, sélectionner l’application créée précédemment. Si vous allez voir votre application, elle devrait maintenant pouvoir interagir avec l’API Sirene.\n\nTestons maintenant l’API Sirene grâce au swagger (onglet Console de l'API) :\n\nPlus bas, dans la documentation interactive se rendre au point d’entrée /siren/{siren} (méthode GET).\nRemplir le champ q avec le SIREN 500569405 (SIREN de Décathlon 😉)\nSi vous avez l’erreur ci-dessous, comprenez-vous pourquoi ?\n\n\nChanger l’application via le menu déroulant : maintenant que vous avez un token valide, soumettez à nouveau la même requête.\n\nVous devriez maintenant avoir cette sortie :\n\nsortie_sirene_decathlon"
  },
  {
    "objectID": "sessions/api.html#récupération-des-données-via-python",
    "href": "sessions/api.html#récupération-des-données-via-python",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "5.3 Récupération des données via Python ",
    "text": "5.3 Récupération des données via Python \nPour la prochaine application, à partir de la question 4, nous allons avoir besoin de créer une classe spéciale permettant à requests de surcharger notre requête d’un jeton d’authentification. Comme elle n’est pas triviale à créer sans connaissance préalable, la voici :\n\nclass BearerAuth(requests.auth.AuthBase):\n    def __init__(self, token):\n        self.token = token\n    def __call__(self, r):\n        r.headers[\"authorization\"] = \"Bearer \" + self.token\n        return r\n\n\n\n\n\n\n\nExercice 5 : les tokens avec Python\n\n\n\n\nCréer une variable token par le biais de getpass.\nUtiliser cette structure de code pour récupérer la donnée voulue\n\nrequests.get(\n    url,\n    auth=BearerAuth(token)\n)\n\nRemplacer l’utilisation de getpass par l’approche variable d’environnement grâce à dotenv.\n\n\n\n\n\nCorrection de l’exercice\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nsiren=\"500569405\"\ntoken = os.getenv(\"TOKEN_API_INSEE\")\nif token is not None:\n    print(\"Token has been retrieved from env var\")\n\nr = requests.get(\n    f\"https://api.insee.fr/entreprises/sirene/V3.11/siren/{siren}\",\n    auth=BearerAuth(token)\n)\n\nsortie_sirene_decathlon = r.json()\nsortie_sirene_decathlon\n\n\n\n\n\n\n\n\nsortie_sirene_decathlon\n\n\n\n\n\n\nNous avons un dataframe avec de nombreux SIRET (bpe). On pourrait vouloir récupérer des infos sur ceux-ci par le biais de l’API. Néanmoins les conditions d’usage de celle-ci sont restrictives : pas plus de 30 appels par minute.\nOn ne peut donc faire une boucle sur notre dataframe sans contrôler le nombre d’appels à la minute. Idéalement, nous ferions de l’envoi par bash qui permet d’envoyer plusieurs enregistrement à la fois dans une seule requête (comme nous avons fait pour les géolocalisations) mais ce n’est pas possible : l’API Sirene est une API pour de la consultation de données ponctuelles, pas du traitement statistique sur de gros volumes.\nL’autre approche possible, que nous allons adopter, est de mettre un temps d’attente entre chaque appel à l’API. Nous allons donc faire une boucle mais, entre chaque itération, mettre un temps de repos de 2 secondes.\n\n\nFonction utile pour cet exercice\nsiret = \"21310001900024\"\n\ndef get_ape(siret: str = \"21310001900024\", token: str = \"\"):\n    info_siret = requests.get(\n        f\"https://api.insee.fr/entreprises/sirene/V3.11/siret/{siret}\",\n        auth=BearerAuth(token)\n    ).json()\n    ape = (info_siret\n        .get(\"etablissement\", {})\n        .get(\"uniteLegale\", {})\n        .get(\"activitePrincipaleUniteLegale\", {})\n    )\n    return ape\n\nget_ape(siret, token)\n\n\n\n\n\n\n\n\nExercice 6 : généraliser des appels à des API\n\n\n\nNous voulons récupérer l’activité pricnipal de nos établissements (le code APE, qui devrait normalement être 84.11Z).\nUtiliser le package time et sa fonction sleep pour marquer un temps d’arrêt lorsqu’on itére sur les dix premières observations de notre dataframe pour récupérer ce code.\n\n\n\n\nCorrection de l’exercice\nimport time\n\nfirst_siret = []\n\nfor index, row in bpe.head(10).iterrows():\n    first_siret += [get_ape(row['SIRET'], token)]\n    time.sleep(2)"
  },
  {
    "objectID": "sessions/api.html#footnotes",
    "href": "sessions/api.html#footnotes",
    "title": "Atelier pour découvrir la récupération de données via des API",
    "section": "Notes de bas de page",
    "text": "Notes de bas de page\n\n\nTechnique consistant à singer le comportement d’un navigateur web et de récupérer de l’information en moissonnant le HTML auquel accède un site web↩︎\nC’est par exemple l’approche adoptée pour construire ces supports. Cela se fait de cette manière.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Masterclass du SSPHub",
    "section": "",
    "text": "Site web en construction"
  },
  {
    "objectID": "index.html#replays-des-sessions",
    "href": "index.html#replays-des-sessions",
    "title": "Masterclass du SSPHub",
    "section": "Replays des sessions",
    "text": "Replays des sessions\nA venir"
  }
]